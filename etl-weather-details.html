<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>ETL Weather Data Pipeline - Details</title>
  <link rel="stylesheet" href="css/styles.css">
</head>
<body>
  <!-- Navbar -->
  <header>
    <nav class="navbar">
      <ul>
        <li><a href="index.html">Home</a></li>
        <li><a href="about.html">About</a></li>
        <li><a href="skills.html">Skills</a></li>
        <li><a href="experience.html">Experience</a></li>
        <li><a href="projects.html" class="active">Projects</a></li>
        <li><a href="resume.html">Resume</a></li>
        
      </ul>
    </nav>
  </header>

  <!-- Project Details Section -->
  <section class="project-details">
    <h1>ETL Weather Data Pipeline</h1>
    <p class="project-intro">
      Designed and implemented a robust ETL pipeline to process real-time weather data, enabling efficient ingestion, transformation, 
      and storage of large-scale data for analytical purposes.
    </p>

    <!-- Highlights -->
    <div class="star-format">
      <h2>Highlights</h2>
      <ul>
        <li><strong>ETL Pipeline:</strong> Built an end-to-end ETL pipeline using Python for data ingestion, cleaning, transformation, and storage.</li>
        <li><strong>Cloud Integration:</strong> Leveraged AWS services including S3 for data storage, Lambda for automation, and Redshift for data warehousing.</li>
        <li><strong>Scalability:</strong> Designed the pipeline to handle high-volume, real-time weather data ingestion and transformation.</li>
      </ul>
    </div>

    <!-- Key Responsibilities -->
    <div class="key-responsibilities">
      <h2>Key Responsibilities</h2>
      <ul>
        <li>Developed a scalable pipeline to ingest weather data from public APIs and external sources.</li>
        <li>Performed data transformation tasks such as cleaning, normalizing, and aggregating data for downstream analytics.</li>
        <li>Deployed the pipeline on AWS using Lambda and integrated it with Redshift for efficient querying and reporting.</li>
        <li>Automated the entire workflow to ensure real-time data availability.</li>
        <li>Built dashboards to visualize weather trends and historical data insights.</li>
      </ul>
    </div>

    <!-- Technical Details -->
    <div class="technical-details">
      <h2>Technical Details</h2>
      <ul>
        <li><strong>Tools:</strong> Python, Pandas, AWS S3, AWS Lambda, Redshift, and Matplotlib.</li>
        <li><strong>Frameworks:</strong> Integrated Apache Airflow for scheduling and orchestration.</li>
        <li><strong>Visualization:</strong> Developed interactive dashboards using Plotly and Dash for weather trend analysis.</li>
      </ul>
    </div>

    <!-- Results -->
    <div class="evaluation-results">
      <h2>Results</h2>
      <ul>
        <li>Improved data ingestion efficiency by 40% through pipeline automation.</li>
        <li>Reduced manual data cleaning efforts by 80% using transformation scripts.</li>
        <li>Enabled real-time analytics by ensuring processed data availability within minutes.</li>
      </ul>
    </div>

    <!-- Visuals Section -->
    <div class="visuals">
      <h2>Visualizations</h2>
      <div class="visual-images">
        <img src="Images/etl_pipeline.png" alt="ETL Pipeline Visualization">
        
      </div>
    </div>

    <!-- GitHub Link -->
    <div class="github-section">
      <a href="https://github.com/amishagarg20/ETLWeather" target="_blank" class="github-link">
        View the Full Project on GitHub
      </a>
    </div>
  </section>

  <!-- Footer -->
  <footer>
    <p>&copy; 2024 Amisha Garg. All rights reserved.</p>
  </footer>
</body>
</html>
